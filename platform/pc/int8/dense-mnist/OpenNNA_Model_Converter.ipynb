{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd93c49a",
   "metadata": {},
   "source": [
    "# 本文将用于从Tensorflow/TFLite中提取Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a5c7f8",
   "metadata": {},
   "source": [
    "## For Dense-Mnist-Int8模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0044234",
   "metadata": {},
   "source": [
    "## 1.从Tensorflow(.h5 File)中提取Conv2D的Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e64ac9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T10:56:20.654004Z",
     "start_time": "2022-08-16T10:56:20.292935Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#以下为一个提取Tensorflow Conv2d卷积weights+bias的函数，会以txt保存在程序目录下\n",
    "def OpenNNA_Conv2d_GetWeights_From_TF(Layer_Number,Para,Weights_Index,Bias_Index,precision):\n",
    "    data_t = precision#\"%8.6f\"\n",
    "    weights_file_path = \"./\"+str(Layer_Number)+\"_conv2d_\"+str(Layer_Number)+\"_weights.txt\"\n",
    "    Weights   = weights[Weights_Index]\n",
    "    bias_file_path = \"./\"+str(Layer_Number)+\"_conv2d_\"+str(Layer_Number)+\"_bias.txt\"\n",
    "    Bias = weights[Bias_Index]\n",
    "\n",
    "    Conv2d_Kernel_size_row = Para[0] #卷积核大小\n",
    "    Conv2d_Kernel_size_col = Para[1] #卷积核大小\n",
    "    Conv2d_Kernel_channel = Para[2] #卷积核通道\n",
    "    Conv2d_Kernel_number = Para[3] #卷积核数量\n",
    "    Conv2d_bias_number = Para[4]  #偏置数量\n",
    "\n",
    "    #tensorflow hwc -> chw\n",
    "    loadData0 = np.swapaxes(Weights, 0, 2)\n",
    "    loadData1 = np.swapaxes(loadData0, 1, 3)\n",
    "    loadData2 = np.swapaxes(loadData1, 0, 1)\n",
    "    txtfile0 = open(weights_file_path, 'w',encoding='UTF-8')\n",
    "    for i in range(0,Conv2d_Kernel_number):\n",
    "        txtfile0.write(\"\\t{\\n\")\n",
    "        for j in range(0,Conv2d_Kernel_channel):\n",
    "            txtfile0.write(\"\\t\\t{\\n\")\n",
    "            for k in range(0,Conv2d_Kernel_size_row):\n",
    "                txtfile0.write(\"\\t\\t\\t{\")\n",
    "                for w in range(0,Conv2d_Kernel_size_col):\n",
    "                   txtfile0.write(data_t%(loadData2[i][j][k][w])+\", \") \n",
    "                txtfile0.write(\"},\\n\")  \n",
    "            txtfile0.write(\"\\t\\t},\\n\")\n",
    "        txtfile0.write(\"\\t},\\n\\n\")\n",
    "    txtfile0.close()\n",
    "    #Bias\n",
    "    txtfile1 = open(bias_file_path, 'w',encoding='UTF-8')\n",
    "    txtfile1.write(\"\\t{\")\n",
    "    for i in range(0,Conv2d_bias_number):\n",
    "        txtfile1.write(data_t%(Bias[i])+\", \")\n",
    "    txtfile1.write(\"}\")\n",
    "    txtfile1.close()\n",
    "    print(\"OpenNNA: Conv2d Layer:%d Weights[%d]+Bias[%d] Get Success!\"%(Layer_Number,Weights_Index,Bias_Index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a88ce9",
   "metadata": {},
   "source": [
    "## 2.从Tensorflow(.h5 File)中提取Dense的Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a64846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T10:58:09.470969Z",
     "start_time": "2022-08-16T10:58:09.461003Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#以下为一个提取Tensorflow Dense卷积weights+bias的函数，会以txt保存在程序目录下\n",
    "def OpenNNA_Dense_GetWeights_From_TF(Layer_Number,Para,Weights_Index,Bias_Index,precision):\n",
    "    data_t = precision#\"%8.6f\"\n",
    "    weights_file_path = \"./\"+str(Layer_Number)+\"_dense_\"+str(Layer_Number)+\"_weights.txt\"\n",
    "    Weights   = weights[Weights_Index]\n",
    "    bias_file_path = \"./\"+str(Layer_Number)+\"_dense_\"+str(Layer_Number)+\"_bias.txt\"\n",
    "    Bias = weights[Bias_Index]\n",
    "    #tensorflow默认的weights存储格式为HWC，在这里需要转为OpenNNA支持的CHW\n",
    "    Dense_Input_Channel = Para[0] #神经元输入channel c\n",
    "    Dense_Input_Row = Para[1] #神经元输入row h\n",
    "    Dense_Input_Col = Para[2] #神经元输入col w\n",
    "    Dense_Units = Para[3] #神经元数量\n",
    "    Dense_bias_number = Para[4]  #偏置数量\n",
    "\n",
    "    dense1_weights = np.swapaxes(Weights,0,1)\n",
    "    txtfile_1 = open(weights_file_path, 'w', encoding='UTF-8')\n",
    "    txtfile_1.write(\"\\n{\")\n",
    "    for i in range(0,Dense_Units):\n",
    "        txtfile_1.write(\"\\n\\t{\")\n",
    "        for j in range(0,Dense_Input_Channel):#c\n",
    "            for k in range(0,Dense_Input_Row):#h\n",
    "                for l in range(0,Dense_Input_Col):#w\n",
    "                    txtfile_1.write(data_t%dense1_weights[i][j+l*Dense_Input_Channel+k*Dense_Input_Channel*Dense_Input_Col]+\",\")\n",
    "        txtfile_1.write(\"},\\n\")\n",
    "    txtfile_1.write(\"\\n}\")\n",
    "    txtfile_1.close()\n",
    "\n",
    "    #提取第一层Dense的bias\n",
    "    txtfile_1 = open(bias_file_path, 'w', encoding='UTF-8')\n",
    "    txtfile_1.write(\"\\n{\")\n",
    "    for i in range(0,Dense_bias_number):\n",
    "        txtfile_1.write(data_t%Bias[i]+\",\")\n",
    "    txtfile_1.write(\"}\")\n",
    "    txtfile_1.close()\n",
    "    print(\"OpenNNA: Dense Layer:%d Weights[%d]+Bias[%d] Get Success!\"%(Layer_Number,Weights_Index,Bias_Index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9211bd3",
   "metadata": {},
   "source": [
    "## 3.加载训练好的模型文件(.h5 File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c587ba0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-16T11:05:48.584349Z",
     "start_time": "2022-08-16T11:05:42.461345Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('Dense-Mnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435820b2",
   "metadata": {},
   "source": [
    "## 4.加载TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c18e73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T18:40:50.909560Z",
     "start_time": "2022-08-21T18:40:47.744642Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: flatten_input\n",
      "shape: [ 1 28 28]\n",
      "type: <class 'numpy.int8'>\n",
      "\n",
      "\n",
      "== Output details ==\n",
      "name: Identity\n",
      "shape: [ 1 10]\n",
      "type: <class 'numpy.int8'>\n",
      "\n",
      "0 | <class 'type'> | flatten_input | Scales: [0.00392157] | zero_points [-128] | (1, 28, 28)\n",
      "1 | <class 'type'> | sequential/flatten/Const | Scales: [] | zero_points [] | (2,)\n",
      "2 | <class 'type'> | sequential/dense/MatMul | Scales: [0.00598583] | zero_points [0] | (128, 784)\n",
      "3 | <class 'type'> | sequential/dense/BiasAdd/ReadVariableOp/resource | Scales: [2.3473825e-05] | zero_points [0] | (128,)\n",
      "4 | <class 'type'> | sequential/dense_1/MatMul | Scales: [0.00680944] | zero_points [0] | (10, 128)\n",
      "5 | <class 'type'> | sequential/dense_1/BiasAdd/ReadVariableOp/resource | Scales: [0.00028163] | zero_points [0] | (10,)\n",
      "6 | <class 'type'> | sequential/flatten/Reshape | Scales: [0.00392157] | zero_points [-128] | (1, 784)\n",
      "7 | <class 'type'> | sequential/dense/MatMul;sequential/dense/Relu;sequential/dense/BiasAdd | Scales: [0.04135826] | zero_points [-128] | (1, 128)\n",
      "8 | <class 'type'> | sequential/dense_1/MatMul;sequential/dense_1/BiasAdd | Scales: [0.18704295] | zero_points [27] | (1, 10)\n",
      "9 | <class 'type'> | Identity | Scales: [0.00390625] | zero_points [-128] | (1, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tflite_model_name = 'Dense-Mnist-int8.tflite'\n",
    "'''\n",
    "Create interpreter, allocate tensors\n",
    "'''\n",
    "tflite_interpreter = tf.lite.Interpreter(model_path=tflite_model_name)\n",
    "tflite_interpreter.allocate_tensors()\n",
    "\n",
    "'''\n",
    "Check input/output details\n",
    "'''\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "print(\"\\n\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])\n",
    "print()\n",
    "'''\n",
    "Run prediction (optional), input_array has input's shape and dtype\n",
    "'''\n",
    "'''\n",
    "tflite_interpreter.set_tensor(input_details[0]['index'], input_array)\n",
    "tflite_interpreter.invoke()\n",
    "output_array = tflite_interpreter.get_tensor(output_details[0]['index'])\n",
    "'''\n",
    "'''\n",
    "This gives a list of dictionaries. \n",
    "'''\n",
    "tensor_details = tflite_interpreter.get_tensor_details()\n",
    "\n",
    "for dict in tensor_details:\n",
    "    i = dict['index']\n",
    "    tensor_name = dict['name']\n",
    "    scales = dict['quantization_parameters']['scales']\n",
    "    zero_points = dict['quantization_parameters']['zero_points']\n",
    "    tensor = tflite_interpreter.tensor(i)()\n",
    "\n",
    "    print(i, \"|\",type, \"|\",tensor_name, \"|\",\"Scales:\",scales, \"|\",\"zero_points\",zero_points, \"|\",tensor.shape)\n",
    "    #print(tensor)\n",
    "    '''\n",
    "    See note below\n",
    "    '''\n",
    "#print(\"\\n\\n\\n\")\n",
    "#print(tflite_interpreter.tensor(2)().shape)#tensor_details排布:List套字典"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd487242",
   "metadata": {},
   "source": [
    "## 5.从Tensorflow(.tflite File)中提取Dense的Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e391338c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T18:41:18.062476Z",
     "start_time": "2022-08-21T18:41:18.039547Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#以下为一个提取Tensorflow Dense卷积weights+bias的函数，会以txt保存在程序目录下\n",
    "def OpenNNA_Dense_GetWeights_From_TFLite(Layer_Number,Para,Weights_Index,Bias_Index,precision):\n",
    "    tflite_interpreter = tf.lite.Interpreter(model_path='dense-mnist-tinyml.tflite')\n",
    "    tflite_interpreter.allocate_tensors()\n",
    "    data_t = precision#\"%8.6f\"\n",
    "    weights_file_path = \"./\"+str(Layer_Number)+\"_dense_\"+str(Layer_Number)+\"_weights.txt\"\n",
    "    Weights   = tflite_interpreter.tensor(Weights_Index)()\n",
    "    bias_file_path = \"./\"+str(Layer_Number)+\"_dense_\"+str(Layer_Number)+\"_bias.txt\"\n",
    "    Bias = tflite_interpreter.tensor(Bias_Index)()\n",
    "    #tflite默认的weights存储格式为CHW，在这里无需要转为OpenNNA支持的CHW\n",
    "    Dense_Input_Channel = Para[0] #神经元输入channel c\n",
    "    Dense_Input_Row = Para[1] #神经元输入row h\n",
    "    Dense_Input_Col = Para[2] #神经元输入col w\n",
    "    Dense_Units = Para[3] #神经元数量\n",
    "    Dense_bias_number = Para[4]  #偏置数量\n",
    "    #print(Weights.shape)\n",
    "    dense1_weights = Weights#np.swapaxes(Weights,0,1)\n",
    "    #dense1_weights = np.swapaxes(Weights,0,1)\n",
    "    print(dense1_weights.shape)\n",
    "    txtfile_1 = open(weights_file_path, 'w', encoding='UTF-8')\n",
    "    txtfile_1.write(\"\\n{\")\n",
    "    for i in range(0,Dense_Units):\n",
    "        txtfile_1.write(\"\\n\\t{\")\n",
    "        for j in range(0,Dense_Input_Channel):#c\n",
    "            for k in range(0,Dense_Input_Row):#h\n",
    "                for l in range(0,Dense_Input_Col):#w\n",
    "                    #txtfile_1.write(data_t%dense1_weights[i][j+l*Dense_Input_Channel+k*Dense_Input_Channel*Dense_Input_Col]+\",\")\n",
    "                    txtfile_1.write(data_t%dense1_weights[i][l+k*Dense_Input_Col+j*Dense_Input_Col*Dense_Input_Row]+\",\")\n",
    "        txtfile_1.write(\"},\\n\")\n",
    "    txtfile_1.write(\"\\n}\")\n",
    "    txtfile_1.close()\n",
    "\n",
    "    #提取第一层Dense的bias\n",
    "    txtfile_1 = open(bias_file_path, 'w', encoding='UTF-8')\n",
    "    txtfile_1.write(\"\\n{\")\n",
    "    for i in range(0,Dense_bias_number):\n",
    "        txtfile_1.write(data_t%Bias[i]+\",\")\n",
    "    txtfile_1.write(\"}\")\n",
    "    txtfile_1.close()\n",
    "    print(\"OpenNNA: Dense Layer:%d Weights[%d]+Bias[%d] Get Success!\"%(Layer_Number,Weights_Index,Bias_Index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59e4883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-21T18:41:21.572489Z",
     "start_time": "2022-08-21T18:41:21.503497Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 784)\n",
      "OpenNNA: Dense Layer:1 Weights[2]+Bias[3] Get Success!\n",
      "(10, 128)\n",
      "OpenNNA: Dense Layer:2 Weights[4]+Bias[5] Get Success!\n"
     ]
    }
   ],
   "source": [
    "OpenNNA_Dense_GetWeights_From_TFLite(1,[1,28,28,128,128],2,3,\"%d\")#第1层Dense\n",
    "OpenNNA_Dense_GetWeights_From_TFLite(2,[1,1,128,10,10],4,5,\"%d\")#第2层Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069f449",
   "metadata": {},
   "source": [
    "### 将MNIST的.jpg转换为c 数组存到.txt中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e223df27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-19T22:13:07.570949Z",
     "start_time": "2022-08-19T22:13:07.549054Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "import numpy as np\n",
    "\n",
    "image_value = tf.io.read_file('./mnist_train/8_36727.jpg')\n",
    "\n",
    "#解码为tensor\n",
    "image_value = tf.io.decode_jpeg(image_value,channels = 1)\n",
    "\n",
    "\n",
    "#image_value = tf.image.resize(image_value, (32,32))#改变像素值为32*32\n",
    "\n",
    "\n",
    "#tensor转array\n",
    "image_value = image_value.numpy()\n",
    "loadData1 = np.swapaxes(image_value, 0, 2)\n",
    "loadData2 = np.swapaxes(loadData1, 1, 2)\n",
    "\n",
    "row = 28\n",
    "col = 28\n",
    "\n",
    "txtfile = open(r'image_8_36727_int8.txt', 'w',encoding='UTF-8')\n",
    "for i in range(0,1):\n",
    "    txtfile.write(\"\\t{\\n\")\n",
    "    for j in range(0,row):\n",
    "        txtfile.write(\"\\t\\t{\")\n",
    "        for k in range(0,col):\n",
    "            #txtfile.write(str(loadData2[i][j][k])+\", \") \n",
    "            txtfile.write(\"%d\"%(loadData2[i][j][k]-128)+\", \") \n",
    "        txtfile.write(\"},\\n\")\n",
    "    txtfile.write(\"\\t},\\n\\n\")\n",
    "txtfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac418fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

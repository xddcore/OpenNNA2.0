{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rX8mhOLljYeM"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T10:02:32.174391Z",
     "start_time": "2022-07-30T10:02:32.160392Z"
    },
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2022-06-03T19:35:34.647685Z",
     "iopub.status.busy": "2022-06-03T19:35:34.647384Z",
     "iopub.status.idle": "2022-06-03T19:35:34.651913Z",
     "shell.execute_reply": "2022-06-03T19:35:34.651145Z"
    },
    "id": "BZSlp3DAjdYf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# 初学者的 TensorFlow 2.0 教程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUNzJc4jTj6G"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://tensorflow.google.cn/tutorials/quickstart/beginner\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\" />在 TensorFlow.org 观看</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/quickstart/beginner.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\" />在 Google Colab 运行</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/quickstart/beginner.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\" />在 GitHub 查看源代码</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/tutorials/quickstart/beginner.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\" />下载笔记本</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEe3i16tQPjo"
   },
   "source": [
    "Note: 我们的 TensorFlow 社区翻译了这些文档。因为社区翻译是尽力而为， 所以无法保证它们是最准确的，并且反映了最新的\n",
    "[官方英文文档](https://tensorflow.google.cn/?hl=en)。如果您有改进此翻译的建议， 请提交 pull request 到\n",
    "[tensorflow/docs](https://github.com/tensorflow/docs) GitHub 仓库。要志愿地撰写或者审核译文，请加入\n",
    "[docs-zh-cn@tensorflow.org Google Group](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-zh-cn)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiH7AC-NTniF"
   },
   "source": [
    "这是一个 [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) 笔记本文件。 Python程序可以直接在浏览器中运行，这是学习 Tensorflow 的绝佳方式。想要学习该教程，请点击此页面顶部的按钮，在Google Colab中运行笔记本。\n",
    "\n",
    "1. 在 Colab中, 连接到Python运行环境： 在菜单条的右上方, 选择 *CONNECT*。\n",
    "2. 运行所有的代码块: 选择 *Runtime* > *Run all*。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnrWf3PCEzXL"
   },
   "source": [
    "下载并安装 TensorFlow 2.0 测试版包。将 TensorFlow 载入你的程序："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T10:02:33.385942Z",
     "start_time": "2022-07-30T10:02:32.176391Z"
    },
    "execution": {
     "iopub.execute_input": "2022-06-03T19:35:34.656029Z",
     "iopub.status.busy": "2022-06-03T19:35:34.655789Z",
     "iopub.status.idle": "2022-06-03T19:35:36.816239Z",
     "shell.execute_reply": "2022-06-03T19:35:36.815233Z"
    },
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "# 安装 TensorFlow\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "载入并准备好 [MNIST 数据集](http://yann.lecun.com/exdb/mnist/)。将样本从整数转换为浮点数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T10:02:33.609942Z",
     "start_time": "2022-07-30T10:02:33.386943Z"
    },
    "execution": {
     "iopub.execute_input": "2022-06-03T19:35:36.821081Z",
     "iopub.status.busy": "2022-06-03T19:35:36.820515Z",
     "iopub.status.idle": "2022-06-03T19:35:37.426114Z",
     "shell.execute_reply": "2022-06-03T19:35:37.425077Z"
    },
    "id": "7FP5258xjs-v"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPZ68wASog_I"
   },
   "source": [
    "将模型的各层堆叠起来，以搭建 `tf.keras.Sequential` 模型。为训练选择优化器和损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T10:09:57.312011Z",
     "start_time": "2022-07-30T10:09:57.262012Z"
    },
    "execution": {
     "iopub.execute_input": "2022-06-03T19:35:37.430669Z",
     "iopub.status.busy": "2022-06-03T19:35:37.430325Z",
     "iopub.status.idle": "2022-06-03T19:35:40.534924Z",
     "shell.execute_reply": "2022-06-03T19:35:40.534010Z"
    },
    "id": "h3IKyzTCDNGo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"le_net_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " average_pooling2d_6 (Averag  (None, 14, 14, 6)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " average_pooling2d_7 (Averag  (None, 5, 5, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 120)               48120     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LeNet-5 model\n",
    "class LeNet(Sequential):\n",
    "  def __init__(self, input_shape, nb_classes):\n",
    "    super().__init__()\n",
    "\n",
    "    self.add(Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=input_shape, padding=\"same\"))\n",
    "    self.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "    self.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
    "    self.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
    "    self.add(Flatten())\n",
    "    self.add(Dense(120, activation='tanh'))\n",
    "    self.add(Dense(84, activation='tanh'))\n",
    "    self.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "    self.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "model = LeNet((28,28,1), 10)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix4mEL65on-w"
   },
   "source": [
    "训练并验证模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T10:11:15.273228Z",
     "start_time": "2022-07-30T10:10:30.766947Z"
    },
    "execution": {
     "iopub.execute_input": "2022-06-03T19:35:40.538765Z",
     "iopub.status.busy": "2022-06-03T19:35:40.538472Z",
     "iopub.status.idle": "2022-06-03T19:36:02.457706Z",
     "shell.execute_reply": "2022-06-03T19:36:02.456798Z"
    },
    "id": "F7dTAzgHDUh7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0319 - accuracy: 0.9898\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0264 - accuracy: 0.9914\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0218 - accuracy: 0.9931\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0193 - accuracy: 0.9939\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0167 - accuracy: 0.9945\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0144 - accuracy: 0.9952\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0138 - accuracy: 0.9954\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0115 - accuracy: 0.9960\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0127 - accuracy: 0.9954\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0096 - accuracy: 0.9969\n",
      "313/313 - 0s - loss: 0.0504 - accuracy: 0.9864 - 419ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05043887719511986, 0.9864000082015991]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4JfEh7kvx6m"
   },
   "source": [
    "现在，这个照片分类器的准确度已经达到 98%。想要了解更多，请阅读 [TensorFlow 教程](https://tensorflow.google.cn/tutorials/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导出模型的相关信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T10:11:23.399803Z",
     "start_time": "2022-07-30T10:11:23.389805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'le_net_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 28, 28, 1), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'conv2d_6_input'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_6', 'trainable': True, 'batch_input_shape': (None, 28, 28, 1), 'dtype': 'float32', 'filters': 6, 'kernel_size': (5, 5), 'strides': (1, 1), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'AveragePooling2D', 'config': {'name': 'average_pooling2d_6', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_7', 'trainable': True, 'dtype': 'float32', 'filters': 16, 'kernel_size': (5, 5), 'strides': (1, 1), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'AveragePooling2D', 'config': {'name': 'average_pooling2d_7', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 84, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T11:50:56.486871Z",
     "start_time": "2022-07-30T11:50:56.472873Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 1, 6)\n",
      "(6,)\n",
      "\n",
      "(5, 5, 6, 16)\n",
      "(16,)\n",
      "\n",
      "(400, 120)\n",
      "(120,)\n",
      "\n",
      "(120, 84)\n",
      "(84,)\n",
      "\n",
      "(84, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "weights = model.get_weights()\n",
    "\n",
    "print(weights[0].shape)#第1层conv2d的weights\n",
    "print(weights[1].shape)#第1层conv2d的bias\n",
    "print()\n",
    "\n",
    "print(weights[2].shape)#第3层conv2d的weights\n",
    "print(weights[3].shape)#第3层conv2d的bias\n",
    "print()\n",
    "\n",
    "print(weights[4].shape)#第6层dense的weights\n",
    "print(weights[5].shape)#第6层dense的bias\n",
    "print()\n",
    "\n",
    "print(weights[6].shape)#第7层dense的weights\n",
    "print(weights[7].shape)#第7层dense的bias\n",
    "print()\n",
    "\n",
    "print(weights[8].shape)#第8层dense的weights\n",
    "print(weights[9].shape)#第8层dense的bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出每一层的权重和偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T12:10:30.275930Z",
     "start_time": "2022-07-30T12:10:30.263929Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#以下为一个提取Tensorflow Conv2d卷积weights+bias的函数，会以txt保存在程序目录下\n",
    "def OpenNNA_Conv2d_GetWeights(Layer_Number,Para,Weights_Index,Bias_Index,precision):\n",
    "    data_t = precision#\"%8.6f\"\n",
    "    weights_file_path = \"./\"+str(Layer_Number)+\"_conv2d_\"+str(Layer_Number)+\"_weights.txt\"\n",
    "    Weights   = weights[Weights_Index]\n",
    "    bias_file_path = \"./\"+str(Layer_Number)+\"_conv2d_\"+str(Layer_Number)+\"_bias.txt\"\n",
    "    Bias = weights[Bias_Index]\n",
    "\n",
    "    Conv2d_Kernel_size_row = Para[0] #卷积核大小\n",
    "    Conv2d_Kernel_size_col = Para[1] #卷积核大小\n",
    "    Conv2d_Kernel_channel = Para[2] #卷积核通道\n",
    "    Conv2d_Kernel_number = Para[3] #卷积核数量\n",
    "    Conv2d_bias_number = Para[4]  #偏置数量\n",
    "\n",
    "    #tensorflow hwc -> chw\n",
    "    loadData0 = np.swapaxes(Weights, 0, 2)\n",
    "    loadData1 = np.swapaxes(loadData0, 1, 3)\n",
    "    loadData2 = np.swapaxes(loadData1, 0, 1)\n",
    "    txtfile0 = open(weights_file_path, 'w',encoding='UTF-8')\n",
    "    for i in range(0,Conv2d_Kernel_number):\n",
    "        txtfile0.write(\"\\t{\\n\")\n",
    "        for j in range(0,Conv2d_Kernel_channel):\n",
    "            txtfile0.write(\"\\t\\t{\\n\")\n",
    "            for k in range(0,Conv2d_Kernel_size_row):\n",
    "                txtfile0.write(\"\\t\\t\\t{\")\n",
    "                for w in range(0,Conv2d_Kernel_size_col):\n",
    "                   txtfile0.write(data_t%(loadData2[i][j][k][w])+\", \") \n",
    "                txtfile0.write(\"},\\n\")  \n",
    "            txtfile0.write(\"\\t\\t},\\n\")\n",
    "        txtfile0.write(\"\\t},\\n\\n\")\n",
    "    txtfile0.close()\n",
    "    #Bias\n",
    "    txtfile1 = open(bias_file_path, 'w',encoding='UTF-8')\n",
    "    txtfile1.write(\"\\t{\")\n",
    "    for i in range(0,Conv2d_bias_number):\n",
    "        txtfile1.write(data_t%(Bias[i])+\", \")\n",
    "    txtfile1.write(\"}\")\n",
    "    txtfile1.close()\n",
    "    print(\"OpenNNA: Conv2d Layer:%d Weights[%d]+Bias[%d] Get Success!\"%(Layer_Number,Weights_Index,Bias_Index))\n",
    "\n",
    "#以下为一个提取Tensorflow Dense卷积weights+bias的函数，会以txt保存在程序目录下\n",
    "def OpenNNA_Dense_GetWeights(Layer_Number,Para,Weights_Index,Bias_Index,precision):\n",
    "    data_t = precision#\"%8.6f\"\n",
    "    weights_file_path = \"./\"+str(Layer_Number)+\"_dense_\"+str(Layer_Number)+\"_weights.txt\"\n",
    "    Weights   = weights[Weights_Index]\n",
    "    bias_file_path = \"./\"+str(Layer_Number)+\"_dense_\"+str(Layer_Number)+\"_bias.txt\"\n",
    "    Bias = weights[Bias_Index]\n",
    "\n",
    "    Dense_Input = Para[0] #神经元输入\n",
    "    Dense_Units = Para[1] #神经元数量\n",
    "    Dense_bias_number = Para[2]  #偏置数量\n",
    "\n",
    "    dense1_weights = np.swapaxes(Weights,0,1)\n",
    "    txtfile_1 = open(weights_file_path, 'w', encoding='UTF-8')\n",
    "    txtfile_1.write(\"\\n{\")\n",
    "    for i in range(0,Dense_Units):\n",
    "        txtfile_1.write(\"\\n\\t{\")\n",
    "        for j in range(0,Dense_Input):\n",
    "            txtfile_1.write(data_t%dense1_weights[i][j]+\",\")\n",
    "        txtfile_1.write(\"},\\n\")\n",
    "    txtfile_1.write(\"\\n}\")\n",
    "    txtfile_1.close()\n",
    "\n",
    "    #提取第一层Dense的bias\n",
    "    txtfile_1 = open(bias_file_path, 'w', encoding='UTF-8')\n",
    "    txtfile_1.write(\"\\n{\")\n",
    "    for i in range(0,Dense_bias_number):\n",
    "        txtfile_1.write(data_t%Bias[i]+\",\")\n",
    "    txtfile_1.write(\"}\")\n",
    "    txtfile_1.close()\n",
    "    print(\"OpenNNA: Dense Layer:%d Weights[%d]+Bias[%d] Get Success!\"%(Layer_Number,Weights_Index,Bias_Index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T12:10:33.751895Z",
     "start_time": "2022-07-30T12:10:33.696895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenNNA: Conv2d Layer:1 Weights[0]+Bias[1] Get Success!\n",
      "OpenNNA: Conv2d Layer:3 Weights[2]+Bias[3] Get Success!\n",
      "OpenNNA: Dense Layer:6 Weights[4]+Bias[5] Get Success!\n",
      "OpenNNA: Dense Layer:7 Weights[6]+Bias[7] Get Success!\n",
      "OpenNNA: Dense Layer:8 Weights[8]+Bias[9] Get Success!\n"
     ]
    }
   ],
   "source": [
    "OpenNNA_Conv2d_GetWeights(1,[5,5,1,6,6],0,1,\"%8.6f\")#第一层Conv2d\n",
    "OpenNNA_Conv2d_GetWeights(3,[5,5,6,16,16],2,3,\"%8.6f\")#第三层Conv2d\n",
    "OpenNNA_Dense_GetWeights(6,[400,120,120],4,5,\"%8.6f\")#第6层Dense\n",
    "OpenNNA_Dense_GetWeights(7,[120,84,84],6,7,\"%8.6f\")#第7层Dense\n",
    "OpenNNA_Dense_GetWeights(8,[84,10,10],8,9,\"%8.6f\")#第8层Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载Mnist数据集，并转换为.jpg文件存储在文件夹下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-13T16:44:07.755198Z",
     "start_time": "2022-07-13T16:43:56.498663Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    " \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "str_1 = 'mnist_train'\n",
    "\n",
    "str_2 = 'mnist_test'\n",
    "\n",
    "if os.path.exists(str_1) is False:\n",
    "\n",
    "    os.mkdir(str_1)\n",
    "\n",
    " \n",
    "\n",
    "if os.path.exists(str_2) is False:\n",
    "\n",
    "    os.mkdir(str_2)\n",
    "\n",
    "#自动下载mnist数据集\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    " \n",
    "\n",
    "for i in range(0, 59999):  # 迭代 0 到 59999 之间的数字\n",
    "\n",
    "    fileName = str_1+\"/\"+ str(Y_train[i]) + \"_\" + str(i) + \".jpg\"\n",
    "\n",
    "    cv2.imwrite(fileName, X_train[i])\n",
    "\n",
    " \n",
    "\n",
    "for i in range(0, 9999):  # 迭代 0 到 9999 之间的数字\n",
    "\n",
    "    fileName = str_2+\"/\"+ str(Y_test[i]) + \"_\" + str(i) + \".jpg\"\n",
    "\n",
    "    cv2.imwrite(fileName, X_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将MNIST的.jpg转换为c 数组存到.txt中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-13T17:20:33.920550Z",
     "start_time": "2022-07-13T17:20:33.906551Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "import numpy as np\n",
    "\n",
    "image_value = tf.io.read_file('./mnist_train/5_0.jpg')\n",
    "\n",
    "#解码为tensor\n",
    "image_value = tf.io.decode_jpeg(image_value,channels = 1)\n",
    "\n",
    "\n",
    "#image_value = tf.image.resize(image_value, (32,32))#改变像素值为32*32\n",
    "\n",
    "\n",
    "#tensor转array\n",
    "image_value = image_value.numpy()\n",
    "loadData1 = np.swapaxes(image_value, 0, 2)\n",
    "loadData2 = np.swapaxes(loadData1, 1, 2)\n",
    "\n",
    "row = 28\n",
    "col = 28\n",
    "\n",
    "txtfile = open(r'image_5_0.txt', 'w',encoding='UTF-8')\n",
    "for i in range(0,1):\n",
    "    txtfile.write(\"\\t{\\n\")\n",
    "    for j in range(0,row):\n",
    "        txtfile.write(\"\\t\\t{\")\n",
    "        for k in range(0,col):\n",
    "            #txtfile.write(str(loadData2[i][j][k])+\", \") \n",
    "            txtfile.write(\"%8.6f\"%(loadData2[i][j][k]/255.0)+\", \") \n",
    "        txtfile.write(\"},\\n\")\n",
    "    txtfile.write(\"\\t},\\n\\n\")\n",
    "txtfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "beginner.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
